PROJEKT: CloudyWithAChanceOfFeedback
Region: eu-north-1 (Comprehend: eu-central-1)

------------------------------------------------------------
TAG 1 – Projekt & GitHub Setup
------------------------------------------------------------

- GitHub Repository erstellt (public)
- Repo-Name: cloudy-with-a-chance-of-feedback
- Lokales Cloning durchgeführt
- Ordnerstruktur angelegt:
  - frontend/
  - backend/
  - terraform/
  - k8s/
  - .github/
- .gitignore erstellt und erweitert
- README.md angelegt
- AWS Budget Alert eingerichtet
- Erster Commit + Push durchgeführt

Status: Abgeschlossen


------------------------------------------------------------
TAG 2 – Backend lokal starten
------------------------------------------------------------

- Spring Boot Projekt über Spring Initializr erstellt
- Java 17 verwendet
- Maven Projektstruktur
- H2 In-Memory Datenbank konfiguriert
- H2 Console aktiviert
- Security lokal deaktiviert (Development Mode)
- Erste Test-API erstellt (/api/test)
- Feedback Entity erstellt
- FeedbackRepository erstellt
- FeedbackController erstellt
- POST /api/feedback implementiert
- GET /api/feedback implementiert
- Speicherung in H2 erfolgreich getestet

Status: Abgeschlossen


------------------------------------------------------------
TAG 3 – AWS ML lokal testen
------------------------------------------------------------

- AWS SSO Login erfolgreich eingerichtet
- AWS SDK v2 integriert
- SSO + SSOOIDC Module eingebunden
- Region-Problem erkannt:
  - Comprehend nicht verfügbar in eu-north-1
  - Lösung: Comprehend in eu-central-1 gesetzt
- ComprehendService implementiert
- FeedbackService implementiert
- Sentiment-Analyse integriert
- Keyword-Extraction integriert
- 15 Testfeedback-Texte angelegt (POSITIVE / NEGATIVE / MIXED / NEUTRAL)
- ML Responses erfolgreich validiert
- Confidence Scores als echtes JSON formatiert
- Locale-Problem (Komma statt Punkt) gelöst mit Locale.US
- KeyPhrases als JSON Array gespeichert

Ergebnis:
- Sentiment wird korrekt erkannt
- Confidence wird korrekt als JSON gespeichert
- KeyPhrases werden korrekt extrahiert
- Backend vollständig ML-fähig

Status: Abgeschlossen


------------------------------------------------------------
TAG 4 – Terraform Bootstrap (Remote State)
------------------------------------------------------------

- Terraform Ordnerstruktur erweitert:
  - terraform/bootstrap/
- providers.tf erstellt
- main.tf erstellt
- variables.tf vorbereitet
- outputs.tf vorbereitet

- S3 Bucket für Remote State erstellt:
  - Name: cloudy-feedback-tfstate-eu-central-1
  - Versionierung aktiviert
  - Server-Side Encryption (AES256) aktiviert
  - Projekt-Tags gesetzt

- DynamoDB Tabelle für Terraform Locking erstellt:
  - Name: cloudy-feedback-terraform-locks
  - Billing Mode: PAY_PER_REQUEST
  - LockID als Hash Key definiert
  - Projekt-Tags gesetzt

- Terraform init erfolgreich durchgeführt
- terraform plan geprüft
- terraform apply erfolgreich ausgeführt
- Backend-Konfiguration auf S3 + DynamoDB umgestellt
- State Migration von lokal nach S3 erfolgreich durchgeführt
- Remote State in AWS Console validiert
- .gitignore geprüft (.terraform, *.tfstate ausgeschlossen)
- Commit + Push durchgeführt

Ergebnis:
- Terraform Remote State aktiv
- State liegt sicher in S3
- Locking via DynamoDB funktioniert
- Projekt entspricht Enterprise Best Practices
- Infrastruktur-Phase sauber gestartet

Status: Abgeschlossen

------------------------------------------------------------
TAG 5 – Terraform Network Layer
------------------------------------------------------------

- Network Modul erstellt:
  - terraform/modules/network/
  - main.tf
  - variables.tf
  - outputs.tf

- Root Terraform Struktur aufgebaut:
  - backend.tf (S3 + DynamoDB Remote State)
  - providers.tf (AWS Provider eu-central-1)
  - main.tf (Network Modul eingebunden)

- VPC erstellt:
  - CIDR: 10.0.0.0/16
  - Name: cloudy-feedback-vpc

- 2 Public Subnets erstellt:
  - eu-central-1a (10.0.1.0/24)
  - eu-central-1b (10.0.2.0/24)

- 2 Private Subnets erstellt:
  - eu-central-1a (10.0.101.0/24)
  - eu-central-1b (10.0.102.0/24)

- Internet Gateway erstellt und angebunden
- Public Route Table erstellt
- 0.0.0.0/0 Route auf IGW gesetzt
- Route Table Associations konfiguriert

- KEIN NAT Gateway verwendet (Projektregel v2)
- Remote State korrekt genutzt (network/terraform.tfstate)
- Terraform apply erfolgreich ausgeführt
- Commit + Push durchgeführt

Ergebnis:
- Netzwerkbasis für EKS und RDS steht
- Multi-AZ vorbereitet
- Infrastruktur Enterprise-konform modularisiert

Status: Abgeschlossen

------------------------------------------------------------
TAG 5 – Cognito OAuth + JWT Validation (Teil 2)
------------------------------------------------------------

- AWS Cognito User Pool final konfiguriert
- Authorization Code Flow per Browser validiert
- Token Exchange via curl + jq erfolgreich getestet
- access_token enthält cognito:groups Claim
- Spring Boot Resource Server aktiviert
- SecurityConfig produktionsreif angepasst:
  - /api/feedback nur für ROLE_ADMIN
  - Custom JwtAuthenticationConverter implementiert
  - cognito:groups → Authorities Mapping korrekt umgesetzt
- 200 Test mit ROLE_ADMIN erfolgreich
- 403 Test ohne ROLE_ADMIN erfolgreich
- Rollenprüfung serverseitig vollständig validiert
- JWT Decode-Regel im Master-Prompt ergänzt

Ergebnis:
- OAuth Flow vollständig funktionsfähig
- JWT Signaturprüfung korrekt
- Rollenprüfung produktionsreif umgesetzt
- Woche 1 Security-Ziel vollständig erreicht

Status: Abgeschlossen


------------------------------------------------------------
TAG 6 – Dockerisierung + ECR Integration
------------------------------------------------------------

- Dockerfile (Multi-Stage Build, Temurin 21) erstellt
- .dockerignore sauber konfiguriert
- Backend erfolgreich containerisiert
- Container lokal getestet (Port 8080, H2, Security 401 geprüft)
- Git-Commit-SHA als Docker-Tag etabliert (kein :latest)
- Zusammenhang Git SHA ↔ Docker Tag ↔ ECR ↔ Rollback vollständig verstanden
- Aktuellen Commit-SHA aus Git ausgelesen
- Docker Image mit Commit-SHA versioniert
- ECR Repository (eu-central-1) erstellt
- Docker Login zu ECR durchgeführt
- Versioniertes Image erfolgreich nach ECR gepusht
- Image in AWS Console validiert
- Commit-Format vereinheitlicht (ab Tag 6: "Tag X: Beschreibung")

Ergebnis:
- Versionierte Docker-Images bilden reproduzierbare Deployments
- Rollback-Fähigkeit durch gespeicherte Images gegeben
- Basis für EKS Deployment vorbereitet
- Woche 2 technisch sauber gestartet

Status: Abgeschlossen

------------------------------------------------------------
TAG 7 – EKS Cluster + ALB Controller
------------------------------------------------------------

- ECR Lifecycle Policy erstellt (Kostenkontrolle / Image Cleanup)
- EKS Modul-Struktur refactored:
  - modules/vpc/
  - modules/eks/
  - modules/security-groups/
- Security Group Modul ausgelagert (Projektvorgabe Struktur eingehalten)
- Terraform State bewusst neu aufgebaut (Modul-Umbenennung)

- EKS Cluster erstellt (eu-central-1)
- Managed Node Group konfiguriert:
  - desired=1
  - min=0
  - max=4
  - Public Subnets (laut Projektvorgabe)

- kubeconfig erfolgreich aktualisiert
- kubectl Verbindung zum Cluster validiert
- Node Status "Ready" erfolgreich geprüft

- OIDC Provider für EKS in IAM registriert
- IAM Policy für AWS Load Balancer Controller erstellt
- IAM Role for Service Account (IRSA) eingerichtet
- Helm installiert
- AWS Load Balancer Controller deployed
- Controller Pods im kube-system Namespace Running

- Node Group auf desired=0 skaliert (Kostenkontrolle)
- EC2 Instanz vollständig terminiert
- kubectl get nodes → No resources found

Ergebnis:
- Voll funktionsfähiger EKS Cluster
- Infrastruktur modular und projektkonform
- ALB Ingress vorbereitet
- Kostenkontrolle korrekt umgesetzt
- Woche 2 – Tag 3 vollständig abgeschlossen

Status: Abgeschlossen

------------------------------------------------------------
TAG 8 – RDS PostgreSQL (Terraform, Private Subnets)
------------------------------------------------------------

- RDS Modul erstellt:
  - terraform/modules/rds/
  - main.tf
  - variables.tf
  - outputs.tf

- DB Subnet Group implementiert (Private Subnets only)
- RDS PostgreSQL erstellt:
  - Engine: PostgreSQL 15
  - Instance: db.t3.micro (Projektvorgabe)
  - publicly_accessible = false
  - multi_az = false (kein Overengineering)

- Eigene RDS Security Group erstellt
- Ingress-Regel implementiert:
  - Nur EKS → RDS Port 5432
  - Kein 0.0.0.0/0 Zugriff

- Root Outputs ergänzt:
  - rds_endpoint
  - rds_port
  - rds_db_name

- Snapshot-Strategie verbessert:
  - skip_final_snapshot = false
  - random_id.snapshot_suffix eingeführt
  - final_snapshot_identifier mit stabilem Zufalls-Suffix
  - Begründung:
    - Verhindert Namenskollisionen
    - Vermeidet timestamp()-Plan-Drift
    - Stabiler Wert im Terraform State

- terraform fmt ausgeführt
- terraform validate erfolgreich
- terraform plan geprüft (5 Ressourcen)
- terraform apply erfolgreich durchgeführt
- RDS Endpoint erfolgreich validiert

Ergebnis:
- PostgreSQL läuft in Private Subnets
- Sicherheitsregeln minimal und korrekt
- Snapshot-Strategie kollisionsfrei und stabil
- Infrastruktur REQUIREMENTS-konform
- RDS Instanz am Tagesende gestoppt (Kostenkontrolle)

Status: Abgeschlossen

------------------------------------------------------------
AKTUELLER PROJEKTSTATUS
------------------------------------------------------------

✔ Backend läuft lokal stabil
✔ ML-Service vollständig integriert
✔ Daten werden korrekt analysiert und gespeichert
✔ Architektur sauber (Controller → Service → AWS → DB)

✔ Terraform Bootstrap abgeschlossen
✔ Remote State in S3 aktiv
✔ DynamoDB Locking aktiv
✔ Enterprise-konforme Terraform-Struktur aufgebaut

✔ Network Layer vollständig implementiert
✔ Cognito OAuth Flow vollständig validiert
✔ JWT Validation + Rollenprüfung produktionsreif

✔ Backend erfolgreich containerisiert
✔ SHA-basierte Docker-Versionierung etabliert (kein :latest)
✔ ECR angebunden und versioniertes Image gespeichert
✔ ECR Lifecycle Policy aktiv (Image Cleanup)

✔ EKS Cluster produktionsbereit erstellt
✔ Managed Node Group konfiguriert (min=0 / max=4)
✔ OIDC Provider + IRSA korrekt eingerichtet
✔ AWS Load Balancer Controller installiert
✔ Nodes sauber auf 0 skaliert (Kostenkontrolle aktiv)

✔ RDS PostgreSQL in Private Subnets implementiert
✔ Snapshot-Strategie mit stabilem Random-Suffix umgesetzt
✔ Infrastruktur vollständig datenbankfähig

Projektphase:
Woche 2 – Infrastruktur abgeschlossen (EKS + RDS)

Nächste Phase:
Backend ↔ RDS Verbindung (Profile + ENV)
Woche 2 – Tag 5: Unit Tests